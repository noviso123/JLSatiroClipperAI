{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "id": "view-in-github",
                "colab_type": "text"
            },
            "source": [
                "# ðŸš€ **JLSatiro Clipper AI - V23.0 Titanium Edition**\n",
                "\n",
                "Bem-vindo ao **JLSatiro Clipper AI**, a plataforma definitiva para criaÃ§Ã£o de cortes virais automatizados.\n",
                "\n",
                "### âš¡ **Recursos Titanium:**\n",
                "- **Smart Crop V2.5**: Rastreamento facial ultra-preciso com MediaPipe (Fixed).\n",
                "- **Hyper-Speed Transcription**: TranscriÃ§Ã£o GPU acelerada com Faster-Whisper.\n",
                "- **Auto-Viral**: GeraÃ§Ã£o automÃ¡tica de Thumbnails e Hooks.\n",
                "- **100% Local**: Otimizado para rodar localmente no Colab com zero delay.\n",
                "\n",
                "---"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "setup-cell"
            },
            "outputs": [ ],
            "source": [
                "#@title 1. ðŸ› ï¸ InstalaÃ§Ã£o do Sistema (Execute e Aguarde)\n",
                "#@markdown Isso instalarÃ¡ todas as dependÃªncias, configurarÃ¡ o ambiente e corrigirÃ¡ bugs conhecidos (ImageMagick, MediaPipe).\n",
                "\n",
                "import os\n",
                "import subprocess\n",
                "import sys\n",
                "\n",
                "print(\"ðŸ’Ž [JLSatiro] Iniciando Setup Titanium V23.0...\")\n",
                "\n",
                "# 1. Verificar GPU\n",
                "print(\"ðŸ–¥ï¸ [1/4] Verificando Hardware...\")\n",
                "try:\n",
                "    subprocess.run([\"nvidia-smi\"], check=True)\n",
                "    print(\"   âœ… GPU NVIDIA Detectada! Modo Turbo Ativado.\")\n",
                "except:\n",
                "    print(\"   âš ï¸ AVISO: GPU nÃ£o detectada. O sistema rodarÃ¡ em modo CPU (lento).\")\n",
                "    print(\"   ðŸ‘‰ Dica: VÃ¡ em 'Runtime' > 'Change runtime type' > 'T4 GPU'.\")\n",
                "\n",
                "# 2. Instalar DependÃªncias do Sistema (APT)\n",
                "print(\"ðŸ“¦ [2/4] Instalando Motores de Sistema (FFmpeg, ImageMagick)...\")\n",
                "subprocess.run(\"apt-get update -qq\", shell=True)\n",
                "subprocess.run(\"apt-get install -y ffmpeg imagemagick libsndfile1 sox -qq\", shell=True)\n",
                "\n",
                "# CORREÃ‡ÃƒO: ImageMagick Policy p/ MoviePy\n",
                "if os.path.exists(\"/etc/ImageMagick-6/policy.xml\"):\n",
                "    print(\"   ðŸ”§ Aplicando Patch no ImageMagick...\")\n",
                "    subprocess.run(\"sed -i 's/none/read,write/g' /etc/ImageMagick-6/policy.xml\", shell=True)\n",
                "\n",
                "# 3. Instalar Bibliotecas Python (PIP)\n",
                "print(\"ðŸ [3/4] Instalando Bibliotecas Python (Isso pode levar 2-3 min)...\")\n",
                "\n",
                "# GPU LLM Compilation (Critical for Speed)\n",
                "print(\"   ðŸ§  Compilando Llama.cpp com suporte CUDA (GPU)...\")\n",
                "subprocess.run('CMAKE_ARGS=\"-DGGML_CUDA=on\" pip install llama-cpp-python --no-cache-dir', shell=True)\n",
                "\n",
                "libraries = [\n",
                "    # Core AI\n",
                "    \"torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\",\n",
                "    \"faster-whisper>=1.0.0\",\n",
                "    \"openai-whisper\",\n",
                "    \"mediapipe>=0.10.14\",\n",
                "    \"transformers\",\n",
                "    \n",
                "    # LLM & Logic (Version Locked)\n",
                "    \"instructor>=0.5.0,<1.0.0\",\n",
                "    \"pydantic\",\n",
                "    \n",
                "    # Media Processing\n",
                "    \"moviepy\",\n",
                "    \"opencv-python-headless\",\n",
                "    \"librosa\",\n",
                "    \"soundfile\",\n",
                "    \"imageio\",\n",
                "    \"imageio-ffmpeg\",\n",
                "    \"pillow\",\n",
                "    \"pydub\",\n",
                "\n",
                "    # Web & Utils\n",
                "    \"gradio>=4.0.0,<5.0.0\",\n",
                "    \"flask\",\n",
                "    \"flask-cors\",\n",
                "    \"pytubefix>=6.0.0\",\n",
                "    \"yt-dlp\",\n",
                "    \"python-dotenv\",\n",
                "    \"numpy<2.0.0\",\n",
                "    \"pandas\",\n",
                "    \"edge-tts\"\n",
                "]\n",
                "\n",
                "pip_cmd = f\"{sys.executable} -m pip install --upgrade --no-cache-dir\"\n",
                "for lib in libraries:\n",
                "    subprocess.run(f\"{pip_cmd} \\\"{lib}\\\"\", shell=True, stdout=subprocess.DEVNULL)\n",
                "\n",
                "print(\"   âœ… DependÃªncias Python instaladas.\")\n",
                "\n",
                "# 4. Clonar RepositÃ³rio e Configurar Workspace\n",
                "print(\"ðŸ“‚ [4/4] Configurando Workspace...\")\n",
                "repo_url = \"https://github.com/noviso123/JLSatiroClipperAI.git\"\n",
                "repo_dir = \"/content/JLSatiroClipperAI\"\n",
                "\n",
                "if not os.path.exists(repo_dir):\n",
                "    subprocess.run(f\"git clone {repo_url} {repo_dir}\", shell=True)\n",
                "else:\n",
                "    subprocess.run(f\"cd {repo_dir} && git pull\", shell=True)\n",
                "\n",
                "# Criar pastas necessÃ¡rias\n",
                "os.makedirs(f\"{repo_dir}/downloads\", exist_ok=True)\n",
                "os.makedirs(f\"{repo_dir}/temp_work\", exist_ok=True)\n",
                "os.makedirs(f\"{repo_dir}/backend/models\", exist_ok=True)\n",
                "\n",
                "print(\"\\nâœ¨ INSTALAÃ‡ÃƒO COMPLETA! Execute a prÃ³xima cÃ©lula para iniciar.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "id": "launch-cell"
            },
            "outputs": [ ],
            "source": [
                "#@title 2. ðŸš€ Iniciar JLSatiro Clipper AI\n",
                "#@markdown Clique no play e aguarde o link pÃºblico `https://xxxx.gradio.live` aparecer abaixo.\n",
                "\n",
                "import os\n",
                "import sys\n",
                "\n",
                "# Garantir que estamos no diretÃ³rio correto\n",
                "os.chdir(\"/content/JLSatiroClipperAI\")\n",
                "\n",
                "# ForÃ§ar patch do MediaPipe caso o repo nÃ£o tenha atualizado ainda (Backup Safety)\n",
                "video_engine_path = \"backend/video_engine.py\"\n",
                "if os.path.exists(video_engine_path):\n",
                "    with open(video_engine_path, 'r', encoding='utf-8') as f:\n",
                "        content = f.read()\n",
                "    \n",
                "    if \"from mediapipe import solutions\" in content:\n",
                "        print(\"ðŸ”§ Aplicando correÃ§Ã£o hotfix no MediaPipe (Backup)...\")\n",
                "        content = content.replace(\n",
                "            \"from mediapipe import solutions\\n\\n        mp_face_detection = solutions.face_detection\",\n",
                "            \"import mediapipe as mp\\n\\n        mp_face_detection = mp.solutions.face_detection\"\n",
                "        )\n",
                "        content = content.replace(\n",
                "            \"from mediapipe import solutions\\n\\n        mp_face = solutions.face_detection\",\n",
                "            \"import mediapipe as mp\\n\\n        mp_face = mp.solutions.face_detection\"\n",
                "        )\n",
                "        with open(video_engine_path, 'w', encoding='utf-8') as f:\n",
                "            f.write(content)\n",
                "\n",
                "# Executar App\n",
                "!python app.py"
            ]
        }
    ],
    "metadata": {
        "colab": {
            "provenance": [ ]
        },
        "kernelspec": {
            "display_name": "Python 3",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0
}
